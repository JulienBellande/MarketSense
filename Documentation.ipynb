{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarketSense\n",
    "\n",
    "**MarketSense** simule le rÃ´le dâ€™un **Data Engineer Analytics** spÃ©cialisÃ© en IA. Lâ€™objectif est de crÃ©er un **dashboard dâ€™aide Ã  la dÃ©cision** pour des investisseurs intraday et long terme. Le projet comprend des **pipelines de traitement des donnÃ©es**, un modÃ¨le **GRU** pour prÃ©dire les marchÃ©s financiers, et une application **Streamlit** pour la visualisation.\n",
    "\n",
    "Le code est conÃ§u avec des **classes Python** et suit une approche orientÃ©e objet pour maintenir une bonne scalabilitÃ© et modularitÃ©.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Architecture du projet\n",
    "\n",
    "```\n",
    "â”œâ”€â”€ BigQuery\n",
    "â”‚   â””â”€â”€ Database (BigQuery Dataset)\n",
    "â”‚       â””â”€â”€ News_Data\n",
    "â”œâ”€â”€ Cloud Storage\n",
    "â”‚   â””â”€â”€ Wallet Data (CSV)\n",
    "â”œâ”€â”€ GRU_Agent.keras\n",
    "â”œâ”€â”€ GruAgent.py\n",
    "â”œâ”€â”€ IA_research.ipynb\n",
    "â”œâ”€â”€ Pipeline\n",
    "â”‚   â”œâ”€â”€ core/\n",
    "â”‚   â”‚   â””â”€â”€ main_pipeline.py\n",
    "â”‚   â”œâ”€â”€ market_data/\n",
    "â”‚   â”‚   â””â”€â”€ PipeMarketData.py\n",
    "â”‚   â”œâ”€â”€ news_data/\n",
    "â”‚   â”‚   â””â”€â”€ PipeNewsData.py\n",
    "â”‚   â”œâ”€â”€ sentiment_data/\n",
    "â”‚   â”‚   â””â”€â”€ PipeSentimentData.py\n",
    "â”‚   â”œâ”€â”€ storage/\n",
    "â”‚   â”‚   â””â”€â”€ StorageData.py\n",
    "â”‚   â””â”€â”€ wallet_data/\n",
    "â”‚       â””â”€â”€ PipeWalletData.py\n",
    "â”œâ”€â”€ graph.py\n",
    "â”œâ”€â”€ main.py\n",
    "â””â”€â”€ README.md\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ Pipelines\n",
    "\n",
    "Les pipelines suivent des **bonnes pratiques dâ€™entreprise** pour le traitement des donnÃ©es, garantissant **scalabilitÃ©** et **efficacitÃ©**.\n",
    "\n",
    "- **Extraction** des donnÃ©es, **transformation**, et **stockage** dans **BigQuery** ou **Cloud Storage**.\n",
    "- Les donnÃ©es sont uniformisÃ©es pour un usage en **heure europÃ©enne**.\n",
    "- Lâ€™alimentation des donnÃ©es peut Ãªtre automatisÃ©e pour Ãªtre **continue** en entreprise.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š DonnÃ©es financiÃ¨res â€“ `market_data`\n",
    "\n",
    "Les donnÃ©es proviennent de **Yahoo Finance** via lâ€™API Python `yfinance`.\n",
    "\n",
    "- **Features ajoutÃ©es :**\n",
    "  - `SMA_50` : Moyenne mobile sur 50 pÃ©riodes.\n",
    "  - `Volume_Spike` : DÃ©tection de pics dâ€™activitÃ© (volume supÃ©rieur Ã  deux Ã©carts-types).\n",
    "\n",
    "âš ï¸ Pour du **temps rÃ©el**, une API payante est nÃ©cessaire.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Sentiment de marchÃ© â€“ `sentiment_data`\n",
    "\n",
    "Les donnÃ©es de sentiment proviennent de l'**API CNN Business**.  \n",
    "Cet indicateur mesure la **peur ou la confiance** des investisseurs. Il reflÃ¨te souvent un **effet boule de neige** dans le comportement des marchÃ©s.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“° Infos Ã©conomiques â€“ `news_data`\n",
    "\n",
    "Les informations Ã©conomiques sont extraites dâ€™un **flux RSS** en temps rÃ©el.\n",
    "\n",
    "Ces donnÃ©es sont ensuite transformÃ©es et stockÃ©es dans **BigQuery**, permettant de rÃ©cupÃ©rer facilement les 5 derniÃ¨res actualitÃ©s Ã©conomiques.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¼ DonnÃ©es de portefeuille â€“ `wallet_data`\n",
    "\n",
    "Les investisseurs peuvent fournir un **fichier CSV** de leurs positions (exemple avec `Wallet.csv`). Ce fichier est stockÃ© dans un **Bucket Google Cloud Storage**.\n",
    "\n",
    "Le pipeline :\n",
    "- Calcule le **prix moyen dâ€™achat** par actif.\n",
    "- Calcule la **variation actuelle** du portefeuille (% de gain/perte).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  GRU Agent â€“ `GruAgent.py`\n",
    "\n",
    "AprÃ¨s des expÃ©rimentations dans le notebook `IA_research.ipynb`, un modÃ¨le performant a Ã©tÃ© sauvegardÃ© (`GRU_Agent.keras`).\n",
    "\n",
    "- **Pourquoi GRU ?**\n",
    "  - Plus rapide et moins gourmand que le LSTM.\n",
    "  - Excellente performance en temps rÃ©el pour les prÃ©dictions financiÃ¨res Ã  haute frÃ©quence.\n",
    "\n",
    "Les **GRU** sont des variantes des RNN, largement utilisÃ©s dans le **Deep Learning** pour la prÃ©vision des sÃ©ries temporelles.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Visualisation â€“ `graph.py` & `Streamlit`\n",
    "\n",
    "Les visualisations des donnÃ©es sont rÃ©alisÃ©es via **Streamlit**. Le fichier `graph.py` contient des classes pour simplifier la construction des graphiques et la gestion de l'affichage.\n",
    "\n",
    "ğŸ’¡ Ce type de dashboard pourrait facilement Ãªtre reproduit avec des outils comme **Power BI** ou **Tableau**, largement utilisÃ©s en entreprise pour la visualisation des donnÃ©es.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Main â€“ `main.py`\n",
    "\n",
    "Le fichier `main.py` est le **point dâ€™entrÃ©e** de lâ€™application **Streamlit**.  \n",
    "Il orchestre :\n",
    "\n",
    "- La **mise Ã  jour automatique** des donnÃ©es (chaque heure entre 13h30 et 21h30, horaires de la bourse US).\n",
    "- L'exÃ©cution des **pipelines de traitement des donnÃ©es**.\n",
    "- L'affichage interactif du **dashboard**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ Stockage des donnÃ©es et gestion sur GCP\n",
    "\n",
    "1. **BigQuery** :  \n",
    "   BigQuery est utilisÃ© pour le **stockage des donnÃ©es transformÃ©es**. Cela inclut les donnÃ©es de **sentiment**, **actualitÃ©s**, et les rÃ©sultats des prÃ©dictions du modÃ¨le. La gestion de la base de donnÃ©es est facilitÃ©e grÃ¢ce Ã  BigQuery pour un stockage et une requÃªtabilitÃ© rapide et scalable.\n",
    "\n",
    "2. **Google Cloud Storage (Buckets)** :  \n",
    "   Les donnÃ©es du portefeuille des utilisateurs sont stockÃ©es sous forme de **fichiers CSV** dans des **Buckets Google Cloud Storage**. Ce stockage est utilisÃ© pour la gestion des fichiers volumineux (comme les fichiers CSV) et est directement accessible via des pipelines pour les transformer avant de les stocker dans BigQuery ou d'autres bases de donnÃ©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
